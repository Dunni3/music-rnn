{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce83b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fluidsynth\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import collections\n",
    "from pathlib import Path\n",
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f6d093",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# scrape time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fec86df4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alb_esp1.mid downloaded\n",
      "alb_esp2.mid downloaded\n",
      "alb_esp3.mid downloaded\n",
      "alb_esp4.mid downloaded\n",
      "alb_esp5.mid downloaded\n",
      "alb_esp6.mid downloaded\n",
      "alb_se1.mid downloaded\n",
      "alb_se2.mid downloaded\n",
      "alb_se3.mid downloaded\n",
      "alb_se4.mid downloaded\n",
      "alb_se5.mid downloaded\n",
      "alb_se6.mid downloaded\n",
      "alb_se7.mid downloaded\n",
      "alb_se8.mid downloaded\n",
      "bach_846.mid downloaded\n",
      "bach_847.mid downloaded\n",
      "bach_850.mid downloaded\n",
      "islamei.mid downloaded\n",
      "beethoven_opus10_1.mid downloaded\n",
      "beethoven_opus10_2.mid downloaded\n",
      "beethoven_opus10_3.mid downloaded\n",
      "pathetique_1.mid downloaded\n",
      "pathetique_2.mid downloaded\n",
      "pathetique_3.mid downloaded\n",
      "beethoven_opus22_1.mid downloaded\n",
      "beethoven_opus22_2.mid downloaded\n",
      "beethoven_opus22_3.mid downloaded\n",
      "beethoven_opus22_4.mid downloaded\n",
      "mond_1.mid downloaded\n",
      "mond_2.mid downloaded\n",
      "mond_3.mid downloaded\n",
      "waldstein_1.mid downloaded\n",
      "waldstein_2.mid downloaded\n",
      "waldstein_3.mid downloaded\n",
      "appass_1.mid downloaded\n",
      "appass_2.mid downloaded\n",
      "appass_3.mid downloaded\n",
      "beethoven_les_adieux_1.mid downloaded\n",
      "beethoven_les_adieux_2.mid downloaded\n",
      "beethoven_les_adieux_3.mid downloaded\n",
      "elise.mid downloaded\n",
      "beethoven_opus90_1.mid downloaded\n",
      "beethoven_opus90_2.mid downloaded\n",
      "beethoven_hammerklavier_1.mid downloaded\n",
      "beethoven_hammerklavier_2.mid downloaded\n",
      "beethoven_hammerklavier_3.mid downloaded\n",
      "beethoven_hammerklavier_4.mid downloaded\n",
      "bor_ps1.mid downloaded\n",
      "bor_ps2.mid downloaded\n",
      "bor_ps3.mid downloaded\n",
      "bor_ps4.mid downloaded\n",
      "bor_ps5.mid downloaded\n",
      "bor_ps6.mid downloaded\n",
      "bor_ps7.mid downloaded\n",
      "brahms_opus1_1.mid downloaded\n",
      "brahms_opus1_2.mid downloaded\n",
      "brahms_opus1_3.mid downloaded\n",
      "brahms_opus1_4.mid downloaded\n",
      "br_im2.mid downloaded\n",
      "br_im5.mid downloaded\n",
      "br_im6.mid downloaded\n",
      "brahms_opus117_1.mid downloaded\n",
      "brahms_opus117_2.mid downloaded\n",
      "br_rhap.mid downloaded\n",
      "burg_perlen.mid downloaded\n",
      "burg_quelle.mid downloaded\n",
      "burg_agitato.mid downloaded\n",
      "burg_geschwindigkeit.mid downloaded\n",
      "burg_erwachen.mid downloaded\n",
      "burg_gewitter.mid downloaded\n",
      "burg_sylphen.mid downloaded\n",
      "burg_trennung.mid downloaded\n",
      "burg_spinnerlied.mid downloaded\n",
      "chpn_op7_1.mid downloaded\n",
      "chpn_op7_2.mid downloaded\n",
      "chpn_op10_e01.mid downloaded\n",
      "chpn_op10_e05.mid downloaded\n",
      "chpn_op10_e12.mid downloaded\n",
      "chp_op18.mid downloaded\n",
      "chpn_op23.mid downloaded\n",
      "chpn_op25_e1.mid downloaded\n",
      "chpn_op25_e2.mid downloaded\n",
      "chpn_op25_e3.mid downloaded\n",
      "chpn_op25_e4.mid downloaded\n",
      "chpn_op25_e11.mid downloaded\n",
      "chpn_op25_e12.mid downloaded\n",
      "chpn_op27_1.mid downloaded\n",
      "chpn_op27_2.mid downloaded\n",
      "chpn-p1.mid downloaded\n",
      "chpn-p2.mid downloaded\n",
      "chpn-p3.mid downloaded\n",
      "chpn-p4.mid downloaded\n",
      "chpn-p5.mid downloaded\n",
      "chpn-p6.mid downloaded\n",
      "chpn-p7.mid downloaded\n",
      "chpn-p8.mid downloaded\n",
      "chpn-p9.mid downloaded\n",
      "chpn-p10.mid downloaded\n",
      "chpn-p11.mid downloaded\n",
      "chpn-p12.mid downloaded\n",
      "chpn-p13.mid downloaded\n",
      "chpn-p14.mid downloaded\n",
      "chpn-p15.mid downloaded\n",
      "chpn-p16.mid downloaded\n",
      "chpn-p17.mid downloaded\n",
      "chpn-p18.mid downloaded\n",
      "chpn-p19.mid downloaded\n",
      "chpn-p20.mid downloaded\n",
      "chpn-p21.mid downloaded\n",
      "chpn-p22.mid downloaded\n",
      "chpn-p23.mid downloaded\n",
      "chpn-p24.mid downloaded\n",
      "chp_op31.mid downloaded\n",
      "chpn_op33_2.mid downloaded\n",
      "chpn_op33_4.mid downloaded\n",
      "chpn_op35_1.mid downloaded\n",
      "chpn_op35_2.mid downloaded\n",
      "chpn_op35_3.mid downloaded\n",
      "chpn_op35_4.mid downloaded\n",
      "chpn_op53.mid downloaded\n",
      "chpn_op66.mid downloaded\n",
      "clementi_opus36_1_1.mid downloaded\n",
      "clementi_opus36_1_2.mid downloaded\n",
      "clementi_opus36_1_3.mid downloaded\n",
      "clementi_opus36_2_1.mid downloaded\n",
      "clementi_opus36_2_2.mid downloaded\n",
      "clementi_opus36_2_3.mid downloaded\n",
      "clementi_opus36_3_1.mid downloaded\n",
      "clementi_opus36_3_2.mid downloaded\n",
      "clementi_opus36_3_3.mid downloaded\n",
      "clementi_opus36_4_1.mid downloaded\n",
      "clementi_opus36_4_2.mid downloaded\n",
      "clementi_opus36_4_3.mid downloaded\n",
      "clementi_opus36_5_1.mid downloaded\n",
      "clementi_opus36_5_2.mid downloaded\n",
      "clementi_opus36_5_3.mid downloaded\n",
      "clementi_opus36_6_1.mid downloaded\n",
      "clementi_opus36_6_2.mid downloaded\n",
      "deb_prel.mid downloaded\n",
      "deb_menu.mid downloaded\n",
      "deb_clai.mid downloaded\n",
      "deb_pass.mid downloaded\n",
      "debussy_cc_1.mid downloaded\n",
      "debussy_cc_2.mid downloaded\n",
      "debussy_cc_3.mid downloaded\n",
      "debussy_cc_4.mid downloaded\n",
      "debussy_cc_5.mid downloaded\n",
      "debussy_cc_6.mid downloaded\n",
      "god_chpn_op10_e01.mid downloaded\n",
      "god_alb_esp2.mid downloaded\n",
      "gra_esp_2.mid downloaded\n",
      "gra_esp_3.mid downloaded\n",
      "gra_esp_4.mid downloaded\n",
      "grieg_walzer.mid downloaded\n",
      "grieg_waechter.mid downloaded\n",
      "grieg_elfentanz.mid downloaded\n",
      "grieg_berceuse.mid downloaded\n",
      "grieg_halling.mid downloaded\n",
      "grieg_butterfly.mid downloaded\n",
      "grieg_wanderer.mid downloaded\n",
      "grieg_voeglein.mid downloaded\n",
      "grieg_spring.mid downloaded\n",
      "grieg_album.mid downloaded\n",
      "grieg_march.mid downloaded\n",
      "grieg_zwerge.mid downloaded\n",
      "grieg_brooklet.mid downloaded\n",
      "grieg_wedding.mid downloaded\n",
      "grieg_once_upon_a_time.mid downloaded\n",
      "grieg_kobold.mid downloaded\n",
      "haydn_7_1.mid downloaded\n",
      "haydn_7_2.mid downloaded\n",
      "haydn_7_3.mid downloaded\n",
      "haydn_8_1.mid downloaded\n",
      "haydn_8_2.mid downloaded\n",
      "haydn_8_3.mid downloaded\n",
      "haydn_8_4.mid downloaded\n",
      "haydn_9_1.mid downloaded\n",
      "haydn_9_2.mid downloaded\n",
      "haydn_9_3.mid downloaded\n",
      "haydn_33_1.mid downloaded\n",
      "haydn_33_2.mid downloaded\n",
      "haydn_33_3.mid downloaded\n",
      "haydn_35_1.mid downloaded\n",
      "haydn_35_2.mid downloaded\n",
      "haydn_35_3.mid downloaded\n",
      "hay_40_1.mid downloaded\n",
      "hay_40_2.mid downloaded\n",
      "haydn_43_1.mid downloaded\n",
      "haydn_43_2.mid downloaded\n",
      "haydn_43_3.mid downloaded\n",
      "liz_donjuan.mid downloaded\n",
      "liz_liebestraum.mid downloaded\n",
      "liz_et1.mid downloaded\n",
      "liz_et2.mid downloaded\n",
      "liz_et3.mid downloaded\n",
      "liz_et4.mid downloaded\n",
      "liz_et5.mid downloaded\n",
      "liz_et6.mid downloaded\n",
      "liz_et_trans4.mid downloaded\n",
      "liz_et_trans5.mid downloaded\n",
      "liz_et_trans8.mid downloaded\n",
      "liz_rhap02.mid downloaded\n",
      "liz_rhap09.mid downloaded\n",
      "liz_rhap10.mid downloaded\n",
      "liz_rhap12.mid downloaded\n",
      "liz_rhap15.mid downloaded\n",
      "mendel_op19_1.mid downloaded\n",
      "mendel_op19_2.mid downloaded\n",
      "mendel_op19_3.mid downloaded\n",
      "mendel_op19_4.mid downloaded\n",
      "mendel_op19_5.mid downloaded\n",
      "mendel_op19_6.mid downloaded\n",
      "mendel_op30_1.mid downloaded\n",
      "mendel_op30_2.mid downloaded\n",
      "mendel_op30_3.mid downloaded\n",
      "mendel_op30_4.mid downloaded\n",
      "mendel_op30_5.mid downloaded\n",
      "mendel_op53_5.mid downloaded\n",
      "mendel_op62_3.mid downloaded\n",
      "mendel_op62_4.mid downloaded\n",
      "mendel_op62_5.mid downloaded\n",
      "mos_op36_6.mid downloaded\n",
      "mz_311_1.mid downloaded\n",
      "mz_311_2.mid downloaded\n",
      "mz_311_3.mid downloaded\n",
      "mz_330_1.mid downloaded\n",
      "mz_330_2.mid downloaded\n",
      "mz_330_3.mid downloaded\n",
      "mz_331_1.mid downloaded\n",
      "mz_331_2.mid downloaded\n",
      "mz_331_3.mid downloaded\n",
      "mz_332_1.mid downloaded\n",
      "mz_332_2.mid downloaded\n",
      "mz_332_3.mid downloaded\n",
      "mz_333_1.mid downloaded\n",
      "mz_333_2.mid downloaded\n",
      "mz_333_3.mid downloaded\n",
      "mz_545_1.mid downloaded\n",
      "mz_545_2.mid downloaded\n",
      "mz_545_3.mid downloaded\n",
      "mz_570_1.mid downloaded\n",
      "mz_570_2.mid downloaded\n",
      "mz_570_3.mid downloaded\n",
      "muss_1.mid downloaded\n",
      "muss_2.mid downloaded\n",
      "muss_3.mid downloaded\n",
      "muss_4.mid downloaded\n",
      "muss_5.mid downloaded\n",
      "muss_6.mid downloaded\n",
      "muss_7.mid downloaded\n",
      "muss_8.mid downloaded\n",
      "rac_op3_2.mid downloaded\n",
      "rac_op23_2.mid downloaded\n",
      "rac_op23_3.mid downloaded\n",
      "rac_op23_5.mid downloaded\n",
      "rac_op23_7.mid downloaded\n",
      "rac_op32_1.mid downloaded\n",
      "rac_op32_13.mid downloaded\n",
      "rac_op33_5.mid downloaded\n",
      "rac_op33_6.mid downloaded\n",
      "rac_op33_8.mid downloaded\n",
      "rav_eau.mid downloaded\n",
      "ravel_miroirs_1.mid downloaded\n",
      "rav_ondi.mid downloaded\n",
      "rav_gib.mid downloaded\n",
      "rav_scarbo.mid downloaded\n",
      "schubert_D850_1.mid downloaded\n",
      "schubert_D850_2.mid downloaded\n",
      "schubert_D850_3.mid downloaded\n",
      "schubert_D850_4.mid downloaded\n",
      "schub_d760_1.mid downloaded\n",
      "schub_d760_2.mid downloaded\n",
      "schub_d760_3.mid downloaded\n",
      "schub_d760_4.mid downloaded\n",
      "schumm-1.mid downloaded\n",
      "schumm-2.mid downloaded\n",
      "schumm-3.mid downloaded\n",
      "schumm-4.mid downloaded\n",
      "schumm-5.mid downloaded\n",
      "schumm-6.mid downloaded\n",
      "schu_143_1.mid downloaded\n",
      "schu_143_2.mid downloaded\n",
      "schu_143_3.mid downloaded\n",
      "schuim-1.mid downloaded\n",
      "schuim-2.mid downloaded\n",
      "schuim-3.mid downloaded\n",
      "schuim-4.mid downloaded\n",
      "schubert_d935_1.mid downloaded\n",
      "schubert_d935_2.mid downloaded\n",
      "schubert_d935_3.mid downloaded\n",
      "schubert_d935_4.mid downloaded\n",
      "schub_d960_1.mid downloaded\n",
      "schub_d960_2.mid downloaded\n",
      "schub_d960_3.mid downloaded\n",
      "schub_d960_4.mid downloaded\n",
      "schum_abegg.mid downloaded\n",
      "scn15_1.mid downloaded\n",
      "scn15_2.mid downloaded\n",
      "scn15_3.mid downloaded\n",
      "scn15_4.mid downloaded\n",
      "scn15_5.mid downloaded\n",
      "scn15_6.mid downloaded\n",
      "scn15_7.mid downloaded\n",
      "scn15_8.mid downloaded\n",
      "scn15_9.mid downloaded\n",
      "scn15_10.mid downloaded\n",
      "scn15_11.mid downloaded\n",
      "scn15_12.mid downloaded\n",
      "scn15_13.mid downloaded\n",
      "scn16_1.mid downloaded\n",
      "scn16_2.mid downloaded\n",
      "scn16_3.mid downloaded\n",
      "scn16_4.mid downloaded\n",
      "scn16_5.mid downloaded\n",
      "scn16_6.mid downloaded\n",
      "scn16_7.mid downloaded\n",
      "scn16_8.mid downloaded\n",
      "scn68_10.mid downloaded\n",
      "scn68_12.mid downloaded\n",
      "fruehlingsrauschen.mid downloaded\n",
      "ty_januar.mid downloaded\n",
      "ty_februar.mid downloaded\n",
      "ty_maerz.mid downloaded\n",
      "ty_april.mid downloaded\n",
      "ty_mai.mid downloaded\n",
      "ty_juni.mid downloaded\n",
      "ty_juli.mid downloaded\n",
      "ty_august.mid downloaded\n",
      "ty_september.mid downloaded\n",
      "ty_oktober.mid downloaded\n",
      "ty_november.mid downloaded\n",
      "ty_dezember.mid downloaded\n",
      "bk_xmas4.mid downloaded\n",
      "bk_xmas2.mid downloaded\n",
      "bk_xmas5.mid downloaded\n",
      "bk_xmas3.mid downloaded\n",
      "bk_xmas1.mid downloaded\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "_datadir = Path('./data/classical')\n",
    "def get_artist_link(tag):\n",
    "    if tag.name != 'a':\n",
    "        return False\n",
    "    if tag.parent.name != 'td':\n",
    "        return False\n",
    "    if not tag.parent.has_attr('class'):\n",
    "        return False\n",
    "    if tag.parent.attrs['class'][0] == 'midi':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_files(tag):\n",
    "    if tag.name != 'a':\n",
    "        return False\n",
    "    if tag.parent.name != 'td':\n",
    "        return False\n",
    "    if not tag.parent.has_attr('class'):\n",
    "        return False\n",
    "    if tag.parent.attrs['class'][0] != 'midi':\n",
    "        return False\n",
    "    if tag.has_attr('class'):\n",
    "        return False\n",
    "    href = tag.attrs['href']\n",
    "    if href.split('/')[0] != 'midis':\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "root_url = 'http://www.piano-midi.de/'\n",
    "base_url = f'{root_url}/midi_files.htm'\n",
    "r = requests.get(base_url)\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "composer_page_link = soup.find_all(get_artist_link)\n",
    "for composer_link in composer_page_link:\n",
    "    composer_url = f'{root_url}/{composer_link.attrs[\"href\"]}'\n",
    "    r = requests.get(composer_url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser') \n",
    "    file_tags = soup.find_all(get_files)\n",
    "    for file_tag in file_tags:\n",
    "        href = file_tag.attrs['href']\n",
    "        filename = href.split('/')[-1]\n",
    "        file_url = f'{root_url}/{href}'\n",
    "        r = requests.get(file_url)\n",
    "        with open(_datadir / filename, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        print(f'{filename} downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af7441b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ffeddb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>composer</th>\n",
       "      <th>end_time</th>\n",
       "      <th>expected_tempo</th>\n",
       "      <th>16th_note_duration</th>\n",
       "      <th>roll_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/classical/beethoven_opus22_1.mid</td>\n",
       "      <td>beethoven</td>\n",
       "      <td>399.624004</td>\n",
       "      <td>164.101873</td>\n",
       "      <td>0.091407</td>\n",
       "      <td>4371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/classical/schub_d760_4.mid</td>\n",
       "      <td>schub</td>\n",
       "      <td>206.069698</td>\n",
       "      <td>240.133084</td>\n",
       "      <td>0.062465</td>\n",
       "      <td>3285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/classical/mz_330_3.mid</td>\n",
       "      <td>mz</td>\n",
       "      <td>482.101321</td>\n",
       "      <td>189.367179</td>\n",
       "      <td>0.079211</td>\n",
       "      <td>6086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/classical/beethoven_les_adieux_1.mid</td>\n",
       "      <td>beethoven</td>\n",
       "      <td>341.950341</td>\n",
       "      <td>214.732513</td>\n",
       "      <td>0.069854</td>\n",
       "      <td>4895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/classical/burg_spinnerlied.mid</td>\n",
       "      <td>burg</td>\n",
       "      <td>102.871024</td>\n",
       "      <td>277.682898</td>\n",
       "      <td>0.054018</td>\n",
       "      <td>1904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        file   composer    end_time  \\\n",
       "0      data/classical/beethoven_opus22_1.mid  beethoven  399.624004   \n",
       "1            data/classical/schub_d760_4.mid      schub  206.069698   \n",
       "2                data/classical/mz_330_3.mid         mz  482.101321   \n",
       "3  data/classical/beethoven_les_adieux_1.mid  beethoven  341.950341   \n",
       "4        data/classical/burg_spinnerlied.mid       burg  102.871024   \n",
       "\n",
       "   expected_tempo  16th_note_duration  roll_length  \n",
       "0      164.101873            0.091407         4371  \n",
       "1      240.133084            0.062465         3285  \n",
       "2      189.367179            0.079211         6086  \n",
       "3      214.732513            0.069854         4895  \n",
       "4      277.682898            0.054018         1904  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_datadir = Path('./data/classical')\n",
    "_metadata_file = _datadir / 'metadata.csv'\n",
    "\n",
    "if not _metadata_file.exists():\n",
    "    files = collections.defaultdict(list)\n",
    "    for filepath in _datadir.glob('*.mid'):\n",
    "        files['file'].append(str(filepath))\n",
    "        composer = filepath.stem.split('_')[0]\n",
    "        files['composer'].append(composer)\n",
    "\n",
    "        pm = pretty_midi.PrettyMIDI(str(filepath))\n",
    "        files['end_time'].append(pm.get_end_time())\n",
    "        \n",
    "        \n",
    "        tempos, probabilities = pm.estimate_tempi()\n",
    "        assert np.isclose(sum(probabilities), 1)\n",
    "        tempo_bpm = np.dot(tempos, probabilities) # expected tempo in beats/min\n",
    "        seconds_per_beat = (1/tempo_bpm)*60\n",
    "        time_sig_denom = pm.time_signature_changes[0].denominator\n",
    "        note_dist = seconds_per_beat / (16 / time_sig_denom)\n",
    "        \n",
    "        files['expected_tempo'].append(tempo_bpm)\n",
    "        files['16th_note_duration'].append(note_dist)\n",
    "        roll = midi_to_pianoroll(str(filepath), sample_dist=note_dist)\n",
    "        files['roll_length'].append(roll.shape[1])\n",
    "\n",
    "    df_meta = pd.DataFrame({ key: np.asarray(val) for key, val in files.items() })\n",
    "    df_meta.to_csv(_metadata_file, index=False)\n",
    "else:\n",
    "    df_meta = pd.read_csv(_metadata_file)\n",
    "    \n",
    "    \n",
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bce397",
   "metadata": {
    "tags": []
   },
   "source": [
    "# converting midi to audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7fe1e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sampling rate for audio playback\n",
    "_SAMPLING_RATE = 16000\n",
    "\n",
    "def display_audio(pm: pretty_midi.PrettyMIDI, seconds=30):\n",
    "  waveform = pm.fluidsynth(fs=_SAMPLING_RATE)\n",
    "  # Take a sample of the generated waveform to mitigate kernel resets\n",
    "  waveform_short = waveform[:seconds*_SAMPLING_RATE]\n",
    "  return display.Audio(waveform_short, rate=_SAMPLING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2ac7dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# converting midi to pianoroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "422c33ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def midi_to_pianoroll(file, sample_dist=0.02):\n",
    "    pm = pretty_midi.PrettyMIDI(file)\n",
    "    sampling_rate = 1/sample_dist\n",
    "    piano_roll = pm.get_piano_roll(fs=sampling_rate)\n",
    "    return piano_roll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c60996",
   "metadata": {},
   "source": [
    "# define dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5096c744-6a03-48f9-9a4d-780df90a2a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_dir.is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61eb0a4f-e93f-4a0c-b29b-4a19c0c6483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_files(processed_data_dir):\n",
    "\n",
    "    preprocessed_data = collections.defaultdict(list)\n",
    "    for midi_dir in processed_data_dir.glob('*/'):\n",
    "        if not midi_dir.is_dir():\n",
    "            continue\n",
    "        piece_name = midi_dir.name\n",
    "        chord_file_name = f'{piece_name}_right_C_full.npy'\n",
    "        data_file = midi_dir / chord_file_name\n",
    "        if not data_file.exists():\n",
    "            print(data_file)\n",
    "            raise Exception('shit is fucked!!')\n",
    "\n",
    "        # record piece name and the path of the file containing the full chord data\n",
    "        preprocessed_data['right_full_chord_file'].append(str(data_file))\n",
    "        preprocessed_data['piece_name'].append(piece_name)\n",
    "\n",
    "        # compute the size of the file after \n",
    "        chord_roll = np.load(data_file)\n",
    "        preprocessed_data['chord_roll_size'].append(chord_roll.shape[0])\n",
    "\n",
    "    df_preprocess = pd.DataFrame({ key: np.asarray(val) for key, val in preprocessed_data.items() })\n",
    "    return df_preprocess\n",
    "\n",
    "processed_data_dir = Path('./data/chopin_processed_bin')\n",
    "df_preprocess = get_preprocessed_files(processed_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ebef2d21-e6e3-4593-a043-72a5ebe26dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullChord(Dataset):\n",
    "    \n",
    "    def __init__(self, df_meta: pd.DataFrame, seq_length: int = 25, \n",
    "                 batch_size: int = 20, batch_per_file=None):\n",
    "        self.df_meta = df_meta.copy()\n",
    "\n",
    "        self.df_meta['n_batches'] = (self.df_meta['chord_roll_size'] - seq_length )*0.95 // batch_size\n",
    "        self.df_meta['n_batches'] = self.df_meta['n_batches'].astype(int)\n",
    "        file_idx_ends = []\n",
    "        n_batches = self.df_meta['n_batches'].values\n",
    "        file_idx_ends = [n_batches[0]*batch_size - 1]\n",
    "        for batches_in_file in n_batches[1:]:\n",
    "            file_idx_ends.append(batches_in_file*batch_size + file_idx_ends[-1] )\n",
    "\n",
    "        self.df_meta['file_idx_ends'] = file_idx_ends\n",
    "\n",
    "        \n",
    "        self.seq_length = seq_length\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_per_file = batch_per_file\n",
    "\n",
    "        if self.batch_per_file is not None:\n",
    "            self.idx_per_file = self.batch_size*self.batch_per_file\n",
    "        else:\n",
    "            self.idx_per_file = None\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.batch_per_file is None:\n",
    "            return int(self.df_meta['n_batches'].sum()*self.batch_size)\n",
    "        else:\n",
    "            return self.df_meta.shape[0]*self.idx_per_file\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.batch_per_file is None:\n",
    "            file_idx_ends = self.df_meta['file_idx_ends'].values\n",
    "            for i in range(len(file_idx_ends)):\n",
    "                if idx < file_idx_ends[i]:\n",
    "                    file_idx = i\n",
    "                    break\n",
    "            if file_idx == 0:\n",
    "                idx_start = 0\n",
    "            else:\n",
    "                idx_start = file_idx_ends[file_idx - 1]\n",
    "            window_idx = int(idx - idx_start)\n",
    "        else:\n",
    "            file_idx = idx // self.idx_per_file\n",
    "            window_idx = idx % self.idx_per_file\n",
    "        \n",
    "        \n",
    "        seq, label = self.get_rolls(file_idx, window_idx)\n",
    "        \n",
    "        seq = torch.from_numpy(seq).float()\n",
    "        label = torch.from_numpy(label).float()\n",
    "        return seq, label\n",
    "    \n",
    "    def get_rolls(self, file_idx, window_idx):\n",
    "        file_path = self.df_meta.iloc[file_idx]['right_full_chord_file']\n",
    "        \n",
    "        roll = np.load(file_path)\n",
    "        roll_window = roll[window_idx:window_idx+self.seq_length+1, :]\n",
    "        \n",
    "        seq = roll_window[:-1]\n",
    "        label = roll_window[-1]\n",
    "        return seq, label\n",
    "    \n",
    "    \n",
    "class ChordLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size=1848):\n",
    "        super(ChordLSTM, self).__init__()\n",
    "            \n",
    "        hidden_size = vocab_size // 8\n",
    "            \n",
    "        self.lstm = nn.LSTM(input_size=vocab_size, batch_first=True, num_layers=1, hidden_size=hidden_size)\n",
    "        \n",
    "        self.predict_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size, vocab_size),\n",
    "            nn.Softmax(dim=2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "         \n",
    "        output = self.predict_layer(h_n)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd423099-870a-483b-a787-4a57d7535573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_idx = 0\n",
      "iter_idx = 1\n",
      "iter_idx = 2\n",
      "iter_idx = 3\n",
      "iter_idx = 4\n",
      "iter_idx = 5\n",
      "iter_idx=5, iter=5\n",
      "iter_idx=5, train_loss=7.521861394246419\n",
      "iter_idx=5, test_loss=7.52184399843216\n",
      "iter_idx=5, frac_frames_correct=0.0\n",
      "iter_idx = 6\n",
      "iter_idx = 7\n",
      "iter_idx = 8\n",
      "iter_idx = 9\n",
      "iter_idx = 10\n",
      "iter_idx=10, iter=10\n",
      "iter_idx=10, train_loss=7.52182788848877\n",
      "iter_idx=10, test_loss=7.521803941726684\n",
      "iter_idx=10, frac_frames_correct=0.19062499701976776\n",
      "iter_idx = 11\n",
      "iter_idx = 12\n",
      "iter_idx = 13\n",
      "iter_idx = 14\n",
      "iter_idx = 15\n",
      "iter_idx=15, iter=15\n",
      "iter_idx=15, train_loss=7.521801853179932\n",
      "iter_idx=15, test_loss=7.521310896873474\n",
      "iter_idx=15, frac_frames_correct=0.19062499701976776\n",
      "iter_idx = 16\n",
      "iter_idx = 17\n",
      "iter_idx = 18\n",
      "iter_idx = 19\n",
      "iter_idx = 20\n",
      "iter_idx=20, iter=20\n",
      "iter_idx=20, train_loss=7.516920948028565\n",
      "iter_idx=20, test_loss=7.49155084848404\n",
      "iter_idx=20, frac_frames_correct=0.19062499701976776\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "learning_rate = 1e-3\n",
    "batch_size = 8\n",
    "num_workers = 0\n",
    "\n",
    "processed_data_dir = Path('./data/chopin_processed_bin')\n",
    "df_preprocess = get_preprocessed_files(processed_data_dir)\n",
    "\n",
    "rng = np.random.default_rng(12345)\n",
    "idx = np.arange(df_preprocess.shape[0])\n",
    "n_train = int(0.8*idx.shape[0])\n",
    "train_idx = rng.choice(idx, size=n_train, replace=False)\n",
    "test_idx = idx[~np.in1d(idx, train_idx)]\n",
    "df_train = df_preprocess.iloc[train_idx]\n",
    "df_test = df_preprocess.iloc[test_idx]\n",
    "\n",
    "dset_train = FullChord(df_meta=df_train, \n",
    "                    batch_size=batch_size,\n",
    "                    batch_per_file=None,\n",
    "                    seq_length=seq_length)\n",
    "\n",
    "\n",
    "dset_test = FullChord(df_meta=df_test, \n",
    "                    batch_size=batch_size, \n",
    "                    batch_per_file=20,\n",
    "                    seq_length=seq_length)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(dset_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(dset_test, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "model = ChordLSTM()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "metrics = collections.defaultdict(list)\n",
    "\n",
    "iter_idx = -1\n",
    "train_iterator = iter(train_dataloader)\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "while iter_idx < 20:\n",
    "    iter_idx += 1\n",
    "    print(f'iter_idx = {iter_idx}', flush=True)\n",
    "\n",
    "    try:\n",
    "        features, labels = next(train_iterator)\n",
    "    except StopIteration:\n",
    "        train_iterator = iter(train_dataloader)\n",
    "        features, labels = next(train_iterator)\n",
    "\n",
    "\n",
    "    # compute prediction and loss\n",
    "    pred = model(features)[0, :, :]\n",
    "    loss = loss_fn(pred, labels)\n",
    "\n",
    "    # backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "\n",
    "    # compute metrics every 10 iterations\n",
    "    if iter_idx > 0 and iter_idx % 5 == 0:\n",
    "\n",
    "        metrics['iter'].append(iter_idx)\n",
    "\n",
    "        # compute train loss\n",
    "        train_loss = np.mean(np.asarray(train_losses))\n",
    "        metrics['train_loss'].append(train_loss)\n",
    "        train_losses = []\n",
    "\n",
    "\n",
    "        # test loop\n",
    "        test_loss_fn = nn.CrossEntropyLoss()\n",
    "        test_loss = 0\n",
    "        frames_correct = 0\n",
    "        num_batches = len(test_dataloader)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for features, labels in test_dataloader:\n",
    "                pred = model(features)[0, :, :]\n",
    "                test_loss += test_loss_fn(pred, labels).item()\n",
    "\n",
    "                pred_chords = pred.argmax(axis=1)\n",
    "                label_chords = labels.argmax(axis=1) \n",
    "                equal = torch.eq(pred_chords, label_chords)\n",
    "                frames_correct += torch.sum(equal)\n",
    "        model.train()\n",
    "\n",
    "        frac_frames_correct = frames_correct / (num_batches*batch_size)\n",
    "        avg_test_loss = test_loss / num_batches\n",
    "\n",
    "        metrics['test_loss'].append(avg_test_loss)\n",
    "        metrics['frac_frames_correct'].append(frac_frames_correct)\n",
    "\n",
    "        # save metrics\n",
    "        df_metrics = pd.DataFrame({ key: np.asarray(val) for key, val in metrics.items() })\n",
    "        # df_metrics.to_csv(metrics_file)\n",
    "\n",
    "        for key, val in metrics.items():\n",
    "            print(f'iter_idx={iter_idx}, {key}={val[-1]}')\n",
    "\n",
    "        # save model\n",
    "        # state_file = output_dir / f'model_weights_iter{iter_idx}.pth'\n",
    "        # torch.save(model.state_dict(), state_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2ec6114-e2a0-4763-b8b6-6fa6883d15b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>frac_frames_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>7.521852</td>\n",
       "      <td>7.521848</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>7.521850</td>\n",
       "      <td>7.521825</td>\n",
       "      <td>0.001875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>7.521820</td>\n",
       "      <td>7.521770</td>\n",
       "      <td>0.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>7.521413</td>\n",
       "      <td>7.519488</td>\n",
       "      <td>0.190625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iter  train_loss  test_loss  frac_frames_correct\n",
       "0     5    7.521852   7.521848             0.003125\n",
       "1    10    7.521850   7.521825             0.001875\n",
       "2    15    7.521820   7.521770             0.190000\n",
       "3    20    7.521413   7.519488             0.190625"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b1c50bc-fa7f-43fb-a428-4551161227bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-38a2ba01143f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "for features, labels in iter(test_dataloader):\n",
    "    model(features).argmax(axis=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
